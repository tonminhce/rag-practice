{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFss-ha_NEUc"
      },
      "source": [
        "### Visual Representation\n",
        "\n",
        "<img src=\"https://github.com/NirDiamant/RAG_Techniques/blob/main/images/reliable_rag.svg?raw=1\" alt=\"Reliable-RAG\" width=\"300\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZqvFmm_NEUd"
      },
      "source": [
        "# Package Installation and Imports\n",
        "\n",
        "The cell below installs all necessary packages required to run this notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6ts6VAANEUe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.1.0)\n",
            "Requirement already satisfied: langchain-community in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.4.1)\n",
            "Requirement already satisfied: python-dotenv in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.2.1)\n",
            "Requirement already satisfied: langchain_groq in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.1.0)\n",
            "Requirement already satisfied: langchain_chroma in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.0.0)\n",
            "Requirement already satisfied: langchain_cohere in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.5.0)\n",
            "Requirement already satisfied: beautifulsoup4 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.14.2)\n",
            "Requirement already satisfied: tiktoken in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.12.0)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-1.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting openai\n",
            "  Downloading openai-2.8.1-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.1.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (1.1.0)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (1.0.3)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (2.12.4)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (0.4.47)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (4.15.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.0->langchain) (3.0.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.10)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (2.32.5)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (0.25.0)\n",
            "Requirement already satisfied: anyio in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (4.11.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
            "Requirement already satisfied: idna in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.5)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community) (1.0.0)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community) (2.0.44)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community) (3.13.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community) (2.12.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community) (2.3.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (2.3.0)\n",
            "Requirement already satisfied: greenlet>=1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: groq<1.0.0,>=0.30.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_groq) (0.36.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from groq<1.0.0,>=0.30.0->langchain_groq) (1.9.0)\n",
            "Requirement already satisfied: sniffio in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from groq<1.0.0,>=0.30.0->langchain_groq) (1.3.1)\n",
            "Requirement already satisfied: chromadb<2.0.0,>=1.0.20 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_chroma) (1.3.5)\n",
            "Requirement already satisfied: build>=1.0.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb<2.0.0,>=1.0.20->langchain_chroma) (1.3.0)\n",
            "Requirement already satisfied: pybase64>=1.4.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb<2.0.0,>=1.0.20->langchain_chroma) (1.4.2)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.0.20->langchain_chroma) (0.38.0)\n",
            "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb<2.0.0,>=1.0.20->langchain_chroma) (5.4.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb<2.0.0,>=1.0.20->langchain_chroma) (1.23.2)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb<2.0.0,>=1.0.20->langchain_chroma) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb<2.0.0,>=1.0.20->langchain_chroma) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb<2.0.0,>=1.0.20->langchain_chroma) (1.38.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb<2.0.0,>=1.0.20->langchain_chroma) (0.22.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb<2.0.0,>=1.0.20->langchain_chroma) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb<2.0.0,>=1.0.20->langchain_chroma) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb<2.0.0,>=1.0.20->langchain_chroma) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb<2.0.0,>=1.0.20->langchain_chroma) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb<2.0.0,>=1.0.20->langchain_chroma) (1.76.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb<2.0.0,>=1.0.20->langchain_chroma) (5.0.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb<2.0.0,>=1.0.20->langchain_chroma) (0.20.0)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb<2.0.0,>=1.0.20->langchain_chroma) (34.1.0)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb<2.0.0,>=1.0.20->langchain_chroma) (5.2.0)\n",
            "Requirement already satisfied: rich>=10.11.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb<2.0.0,>=1.0.20->langchain_chroma) (14.2.0)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb<2.0.0,>=1.0.20->langchain_chroma) (4.25.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (2.9.0.post0)\n",
            "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (2.2.1)\n",
            "Requirement already satisfied: cohere<6.0,>=5.18.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_cohere) (5.20.0)\n",
            "Requirement already satisfied: types-pyyaml<7.0.0.0,>=6.0.12.20240917 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_cohere) (6.0.12.20250915)\n",
            "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cohere<6.0,>=5.18.0->langchain_cohere) (1.12.1)\n",
            "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cohere<6.0,>=5.18.0->langchain_cohere) (2.32.4.20250913)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tokenizers>=0.13.2->chromadb<2.0.0,>=1.0.20->langchain_chroma) (1.1.5)\n",
            "Requirement already satisfied: filelock in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb<2.0.0,>=1.0.20->langchain_chroma) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb<2.0.0,>=1.0.20->langchain_chroma) (2025.10.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb<2.0.0,>=1.0.20->langchain_chroma) (1.2.0)\n",
            "Requirement already satisfied: shellingham in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb<2.0.0,>=1.0.20->langchain_chroma) (1.5.4)\n",
            "Requirement already satisfied: typer-slim in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb<2.0.0,>=1.0.20->langchain_chroma) (0.20.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from beautifulsoup4) (2.8)\n",
            "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tiktoken) (2025.11.3)\n",
            "Collecting jiter<1,>=0.10.0 (from openai)\n",
            "  Downloading jiter-0.12.0-cp311-cp311-win_amd64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: pyproject_hooks in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from build>=1.0.3->chromadb<2.0.0,>=1.0.20->langchain_chroma) (1.2.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from build>=1.0.3->chromadb<2.0.0,>=1.0.20->langchain_chroma) (0.4.6)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=4.19.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=4.19.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=4.19.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (0.29.0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (2.43.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (1.9.0)\n",
            "Requirement already satisfied: requests-oauthlib in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (2.0.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (0.10)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (6.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (4.9.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (0.6.1)\n",
            "Requirement already satisfied: coloredlogs in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb<2.0.0,>=1.0.20->langchain_chroma) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb<2.0.0,>=1.0.20->langchain_chroma) (25.9.23)\n",
            "Requirement already satisfied: protobuf in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb<2.0.0,>=1.0.20->langchain_chroma) (6.33.1)\n",
            "Requirement already satisfied: sympy in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb<2.0.0,>=1.0.20->langchain_chroma) (1.14.0)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (8.7.0)\n",
            "Requirement already satisfied: zipp>=3.20 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (3.23.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (1.72.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.38.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.38.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.59b0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opentelemetry-sdk>=1.2.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (0.59b0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich>=10.11.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich>=10.11.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (0.1.2)\n",
            "Requirement already satisfied: click>=8.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer>=0.9.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (8.3.1)\n",
            "Requirement already satisfied: httptools>=0.6.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.0.20->langchain_chroma) (0.7.1)\n",
            "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.0.20->langchain_chroma) (1.1.1)\n",
            "Requirement already satisfied: websockets>=10.4 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.0.20->langchain_chroma) (15.0.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb<2.0.0,>=1.0.20->langchain_chroma) (10.0)\n",
            "Requirement already satisfied: pyreadline3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb<2.0.0,>=1.0.20->langchain_chroma) (3.5.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (3.3.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb<2.0.0,>=1.0.20->langchain_chroma) (1.3.0)\n",
            "Downloading langchain_openai-1.1.0-py3-none-any.whl (84 kB)\n",
            "Downloading openai-2.8.1-py3-none-any.whl (1.0 MB)\n",
            "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
            "   ---------------------------------------- 1.0/1.0 MB 6.1 MB/s  0:00:00\n",
            "Downloading jiter-0.12.0-cp311-cp311-win_amd64.whl (204 kB)\n",
            "Installing collected packages: jiter, openai, langchain-openai\n",
            "\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   ------------- -------------------------- 1/3 [openai]\n",
            "   -------------------------- ------------- 2/3 [langchain-openai]\n",
            "   -------------------------- ------------- 2/3 [langchain-openai]\n",
            "   ---------------------------------------- 3/3 [langchain-openai]\n",
            "\n",
            "Successfully installed jiter-0.12.0 langchain-openai-1.1.0 openai-2.8.1\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install langchain langchain-community python-dotenv langchain_groq langchain_chroma langchain_cohere beautifulsoup4 tiktoken langchain-openai openai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAM2gXxDNEUe"
      },
      "outputs": [],
      "source": [
        "### LLMs\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from '.env' file\n",
        "load_dotenv()\n",
        "\n",
        "os.environ['GROQ_API_KEY'] = os.getenv('GROQ_API_KEY') # For LLM -- llama-3.1-8b (small) & mixtral-8x7b-32768 (large)\n",
        "os.environ['COHERE_API_KEY'] = os.getenv('COHERE_API_KEY') # For embedding\n",
        "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY') # For OpenAI models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00suZserNEUf"
      },
      "source": [
        "### Create Vectorstore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Đang kiểm tra và tự động cài đặt các package cần thiết...\n",
            "Đang cài beautifulsoup4 (và tự động kéo theo tất cả dependency)...\n",
            "Hoàn tất! Từ giờ bạn có thể chạy toàn bộ code RAG mà không còn lỗi thiếu package nữa.\n",
            "tiktoken đã được cài thành công!\n"
          ]
        }
      ],
      "source": [
        "# Chạy cell này 1 lần duy nhất → sau đó mọi package thiếu sẽ tự động được cài đủ\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "def install(package):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", package], \n",
        "                          stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "\n",
        "# Danh sách các package chính bạn sẽ dùng cho RAG + LangChain + Cohere + Chroma\n",
        "packages = [\n",
        "    \"langchain\",\n",
        "    \"langchain-community\", \n",
        "    \"langchain-chroma\",\n",
        "    \"langchain-cohere\",\n",
        "    \"chromadb\",\n",
        "    \"tiktoken\",\n",
        "    \"beautifulsoup4\",\n",
        "    \"lxml\",\n",
        "    \"cohere\",\n",
        "    \"langchain-openai\",\n",
        "    \"openai\"\n",
        "]\n",
        "\n",
        "print(\"Đang kiểm tra và tự động cài đặt các package cần thiết...\")\n",
        "for pkg in packages:\n",
        "    try:\n",
        "        __import__(pkg.replace(\"-\", \"_\"))\n",
        "    except ImportError:\n",
        "        print(f\"Đang cài {pkg} (và tự động kéo theo tất cả dependency)...\")\n",
        "        install(pkg)\n",
        "\n",
        "print(\"Hoàn tất! Từ giờ bạn có thể chạy toàn bộ code RAG mà không còn lỗi thiếu package nữa.\")\n",
        "\n",
        "import importlib, os\n",
        "if 'tiktoken' in sys.modules:\n",
        "    del sys.modules['tiktoken']\n",
        "\n",
        "import tiktoken\n",
        "print(\"tiktoken đã được cài thành công!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmVQ0DqZNEUf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "client=<cohere.client.Client object at 0x000001D8B5EA8ED0> async_client=<cohere.client.AsyncClient object at 0x000001D8BA14ACD0> model='embed-english-v3.0' truncate=None cohere_api_key=SecretStr('**********') embedding_types=['float'] max_retries=3 request_timeout=None user_agent='langchain:partner' base_url=None\n"
          ]
        }
      ],
      "source": [
        "### Build Index\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_cohere import CohereEmbeddings\n",
        "\n",
        "# Set embeddings\n",
        "embedding_model = CohereEmbeddings(model=\"embed-english-v3.0\")\n",
        "print(embedding_model)\n",
        "# Docs to index\n",
        "urls = [\n",
        "    \"https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/?ref=dl-staging-website.ghost.io\",\n",
        "    \"https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-2-reflection/?ref=dl-staging-website.ghost.io\",\n",
        "    \"https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-3-tool-use/?ref=dl-staging-website.ghost.io\",\n",
        "    \"https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-4-planning/?ref=dl-staging-website.ghost.io\",\n",
        "    \"https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-5-multi-agent-collaboration/?ref=dl-staging-website.ghost.io\"\n",
        "]\n",
        "\n",
        "# Load\n",
        "docs = [WebBaseLoader(url).load() for url in urls]\n",
        "docs_list = [item for sublist in docs for item in sublist]\n",
        "\n",
        "# Split\n",
        "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "    chunk_size=500, chunk_overlap=0\n",
        ")\n",
        "doc_splits = text_splitter.split_documents(docs_list)\n",
        "\n",
        "# Add to vectorstore\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=doc_splits,\n",
        "    collection_name=\"rag\",\n",
        "    embedding=embedding_model,\n",
        ")\n",
        "\n",
        "retriever = vectorstore.as_retriever(\n",
        "                search_type=\"similarity\",\n",
        "                search_kwargs={'k': 4}, # number of documents to retrieve\n",
        "            )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXa61y2hNEUf"
      },
      "source": [
        "### Question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mobOs1UQNEUg"
      },
      "outputs": [],
      "source": [
        "question = \"what are the differnt kind of agentic design patterns?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Fq6qJqjNEUg"
      },
      "source": [
        "### Retrieve docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSgzRe2ANEUg"
      },
      "outputs": [],
      "source": [
        "docs = retriever.invoke(question)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gnENuQuNEUg"
      },
      "source": [
        "### Check what our doc looklike"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M83rQ9iCNEUg",
        "outputId": "1cb57899-4820-4294-96b3-2a6caba8e9fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Title: Four AI Agent Strategies That Improve GPT-4 and GPT-3.5 Performance\n",
            "\n",
            "Source: https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/?ref=dl-staging-website.ghost.io\n",
            "\n",
            "Content: GPT-3.5 to GPT-4 is dwarfed by incorporating an iterative agent workflow. Indeed, wrapped in an agent loop, GPT-3.5 achieves up to 95.1%. Open source agent tools and the academic literature on agents are proliferating, making this an exciting time but also a confusing one. To help put this work into perspective, I’d like to share a framework for categorizing design patterns for building agents. My team AI Fund is successfully using these patterns in many applications, and I hope you find them useful.Reflection: The LLM examines its own work to come up with ways to improve it. Tool Use: The LLM is given tools such as web search, code execution, or any other function to help it gather information, take action, or process data.Planning: The LLM comes up with, and executes, a multistep plan to achieve a goal (for example, writing an outline for an essay, then doing online research, then writing a draft, and so on).Multi-agent collaboration: More than one AI agent work together, splitting up tasks and discussing and debating ideas, to come up with better solutions than a single agent would.Next week, I’ll elaborate on these design patterns and offer suggested readings for each.Keep learning!AndrewRead \"Agentic Design Patterns Part 2: Reflection\"Read \"Agentic Design Patterns Part 3, Tool Use\"Read \"Agentic Design Patterns Part 4: Planning\"Read \"Agentic Design Patterns Part 5: Multi-Agent Collaboration\"ShareSubscribe to The BatchStay updated with weekly AI News and Insights delivered to your inboxCoursesThe BatchCommunityCareersAboutContactHelp\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f\"Title: {docs[0].metadata['title']}\\n\\nSource: {docs[0].metadata['source']}\\n\\nContent: {docs[0].page_content}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyWAs4teNEUh"
      },
      "source": [
        "### Check document relevancy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISrO1CVeNEUh"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Data model\n",
        "class GradeDocuments(BaseModel):\n",
        "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
        "\n",
        "    binary_score: str = Field(\n",
        "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
        "    )\n",
        "\n",
        "\n",
        "# LLM with structured output (OpenAI supports tool calling)\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
        "\n",
        "# Prompt\n",
        "system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n\n",
        "    If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
        "    It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
        "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\"\n",
        "grade_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "retrieval_grader = grade_prompt | structured_llm_grader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLBij9xcNEUh"
      },
      "source": [
        "### Filter out the non-relevant docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AohfucKsNEUh",
        "outputId": "04a6c680-c895-4ef3-e60b-d74dad23147c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPT-3.5 to GPT-4 is dwarfed by incorporating an iterative agent workflow. Indeed, wrapped in an agent loop, GPT-3.5 achieves up to 95.1%. Open source agent tools and the academic literature on agents are proliferating, making this an exciting time but also a confusing one. To help put this work into perspective, I’d like to share a framework for categorizing design patterns for building agents. My team AI Fund is successfully using these patterns in many applications, and I hope you find them useful.Reflection: The LLM examines its own work to come up with ways to improve it. Tool Use: The LLM is given tools such as web search, code execution, or any other function to help it gather information, take action, or process data.Planning: The LLM comes up with, and executes, a multistep plan to achieve a goal (for example, writing an outline for an essay, then doing online research, then writing a draft, and so on).Multi-agent collaboration: More than one AI agent work together, splitting up tasks and discussing and debating ideas, to come up with better solutions than a single agent would.Next week, I’ll elaborate on these design patterns and offer suggested readings for each.Keep learning!AndrewRead \"Agentic Design Patterns Part 2: Reflection\"Read \"Agentic Design Patterns Part 3, Tool Use\"Read \"Agentic Design Patterns Part 4: Planning\"Read \"Agentic Design Patterns Part 5: Multi-Agent Collaboration\"ShareSubscribe to The BatchStay updated with weekly AI News and Insights delivered to your inboxCoursesThe BatchCommunityCareersAboutContactHelp \n",
            " --------------------------------------------------\n",
            "binary_score='yes' \n",
            "\n",
            "GPT-3.5 to GPT-4 is dwarfed by incorporating an iterative agent workflow. Indeed, wrapped in an agent loop, GPT-3.5 achieves up to 95.1%. Open source agent tools and the academic literature on agents are proliferating, making this an exciting time but also a confusing one. To help put this work into perspective, I’d like to share a framework for categorizing design patterns for building agents. My team AI Fund is successfully using these patterns in many applications, and I hope you find them useful.Reflection: The LLM examines its own work to come up with ways to improve it. Tool Use: The LLM is given tools such as web search, code execution, or any other function to help it gather information, take action, or process data.Planning: The LLM comes up with, and executes, a multistep plan to achieve a goal (for example, writing an outline for an essay, then doing online research, then writing a draft, and so on).Multi-agent collaboration: More than one AI agent work together, splitting up tasks and discussing and debating ideas, to come up with better solutions than a single agent would.Next week, I’ll elaborate on these design patterns and offer suggested readings for each.Keep learning!AndrewRead \"Agentic Design Patterns Part 2: Reflection\"Read \"Agentic Design Patterns Part 3, Tool Use\"Read \"Agentic Design Patterns Part 4: Planning\"Read \"Agentic Design Patterns Part 5: Multi-Agent Collaboration\"ShareSubscribe to The BatchStay updated with weekly AI News and Insights delivered to your inboxCoursesThe BatchCommunityCareersAboutContactHelp \n",
            " --------------------------------------------------\n",
            "binary_score='yes' \n",
            "\n",
            "opposed to, say, scalable and highly secure code. By decomposing the overall task into subtasks, we can optimize the subtasks better.Perhaps most important, the multi-agent design pattern gives us, as developers, a framework for breaking down complex tasks into subtasks. When writing code to run on a single CPU, we often break our program up into different processes or threads. This is a useful abstraction that lets us decompose a task, like implementing a web browser, into subtasks that are easier to code. I find thinking through multi-agent roles to be a useful abstraction as well.In many companies, managers routinely decide what roles to hire, and then how to split complex projects — like writing a large piece of software or preparing a research report — into smaller tasks to assign to employees with different specialties. Using multiple agents is analogous. Each agent implements its own workflow, has its own memory (itself a rapidly evolving area in agentic technology: how can an agent remember enough of its past interactions to perform better on upcoming ones?), and may ask other agents for help. Agents can also engage in Planning and Tool Use. This results in a cacophony of LLM calls and message passing between agents that can result in very complex workflows. While managing people is hard, it's a sufficiently familiar idea that it gives us a mental framework for how to \"hire\" and assign tasks to our AI agents. Fortunately, the damage from mismanaging an AI agent is much lower than that from mismanaging humans! Emerging frameworks like AutoGen, Crew AI, and LangGraph, provide rich ways to build multi-agent solutions to problems. If you're interested in playing with a fun multi-agent system, also check out ChatDev, an open source implementation of a set of agents that run a virtual software company. I encourage you to check out their GitHub repo and perhaps clone the repo and run the system yourself. While it may not always produce what you want, you might be amazed at how well it does. Like the design pattern of Planning, I find the output quality of multi-agent collaboration hard to predict, especially when allowing agents to interact freely and providing them with multiple tools. The more mature patterns of Reflection and Tool Use are more reliable. I hope you enjoy playing with these agentic design patterns and that they produce amazing results for you! If you're interested \n",
            " --------------------------------------------------\n",
            "binary_score='yes' \n",
            "\n",
            "opposed to, say, scalable and highly secure code. By decomposing the overall task into subtasks, we can optimize the subtasks better.Perhaps most important, the multi-agent design pattern gives us, as developers, a framework for breaking down complex tasks into subtasks. When writing code to run on a single CPU, we often break our program up into different processes or threads. This is a useful abstraction that lets us decompose a task, like implementing a web browser, into subtasks that are easier to code. I find thinking through multi-agent roles to be a useful abstraction as well.In many companies, managers routinely decide what roles to hire, and then how to split complex projects — like writing a large piece of software or preparing a research report — into smaller tasks to assign to employees with different specialties. Using multiple agents is analogous. Each agent implements its own workflow, has its own memory (itself a rapidly evolving area in agentic technology: how can an agent remember enough of its past interactions to perform better on upcoming ones?), and may ask other agents for help. Agents can also engage in Planning and Tool Use. This results in a cacophony of LLM calls and message passing between agents that can result in very complex workflows. While managing people is hard, it's a sufficiently familiar idea that it gives us a mental framework for how to \"hire\" and assign tasks to our AI agents. Fortunately, the damage from mismanaging an AI agent is much lower than that from mismanaging humans! Emerging frameworks like AutoGen, Crew AI, and LangGraph, provide rich ways to build multi-agent solutions to problems. If you're interested in playing with a fun multi-agent system, also check out ChatDev, an open source implementation of a set of agents that run a virtual software company. I encourage you to check out their GitHub repo and perhaps clone the repo and run the system yourself. While it may not always produce what you want, you might be amazed at how well it does. Like the design pattern of Planning, I find the output quality of multi-agent collaboration hard to predict, especially when allowing agents to interact freely and providing them with multiple tools. The more mature patterns of Reflection and Tool Use are more reliable. I hope you enjoy playing with these agentic design patterns and that they produce amazing results for you! If you're interested \n",
            " --------------------------------------------------\n",
            "binary_score='yes' \n",
            "\n"
          ]
        }
      ],
      "source": [
        "docs_to_use = []\n",
        "for doc in docs:\n",
        "    print(doc.page_content, '\\n', '-'*50)\n",
        "    res = retrieval_grader.invoke({\"question\": question, \"document\": doc.page_content})\n",
        "    print(res,'\\n')\n",
        "    if res.binary_score == 'yes':\n",
        "        docs_to_use.append(doc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hIMRFSmNEUh"
      },
      "source": [
        "### Generate Result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HHr24YkNEUi",
        "outputId": "fe119805-f5da-42c3-da06-b1789f374bfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "According to the retrieved documents, there are four main agentic design patterns mentioned:\n",
            "\n",
            "1. Reflection: The LLM examines its own work to come up with ways to improve it.\n",
            "2. Tool Use: The LLM is given tools such as web search, code execution, or any other function to help it gather information, take action, or process data.\n",
            "3. Planning: The LLM comes up with, and executes, a multistep plan to achieve a goal.\n",
            "4. Multi-agent collaboration: More than one AI agent work together, splitting up tasks and discussing and debating ideas, to come up with better solutions than a single agent would.\n",
            "\n",
            "These design patterns are discussed in the articles \"Four AI Agent Strategies That Improve GPT-4 and GPT-3.5 Performance\" and \"Agentic Design Patterns Part 2: Reflection\", \"Agentic Design Patterns Part 3, Tool Use\", \"Agentic Design Patterns Part 4: Planning\", and \"Agentic Design Patterns Part 5: Multi-Agent Collaboration\".\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# Prompt\n",
        "system = \"\"\"You are an assistant for question-answering tasks. Answer the question based upon your knowledge.\n",
        "Use three-to-five sentences maximum and keep the answer concise.\"\"\"\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"Retrieved documents: \\n\\n <docs>{documents}</docs> \\n\\n User question: <question>{question}</question>\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# LLM\n",
        "llm = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0)\n",
        "\n",
        "# Post-processing\n",
        "def format_docs(docs):\n",
        "    return \"\\n\".join(f\"<doc{i+1}>:\\nTitle:{doc.metadata['title']}\\nSource:{doc.metadata['source']}\\nContent:{doc.page_content}\\n</doc{i+1}>\\n\" for i, doc in enumerate(docs))\n",
        "\n",
        "# Chain\n",
        "rag_chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "# Run\n",
        "generation = rag_chain.invoke({\"documents\":format_docs(docs_to_use), \"question\": question})\n",
        "print(generation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pcm6R1NFNEUi"
      },
      "source": [
        "### Check for Hallucinations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krzRPhG0NEUi",
        "outputId": "b77f9c2d-48a6-4aaf-e2b4-b81087312885"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "binary_score='yes'\n"
          ]
        }
      ],
      "source": [
        "# Data model\n",
        "class GradeHallucinations(BaseModel):\n",
        "    \"\"\"Binary score for hallucination present in 'generation' answer.\"\"\"\n",
        "\n",
        "    binary_score: str = Field(\n",
        "        ...,\n",
        "        description=\"Answer is grounded in the facts, 'yes' or 'no'\"\n",
        "    )\n",
        "\n",
        "# LLM with function call\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "structured_llm_grader = llm.with_structured_output(GradeHallucinations)\n",
        "\n",
        "# Prompt\n",
        "system = \"\"\"You are a grader assessing whether an LLM generation is grounded in / supported by a set of retrieved facts. \\n\n",
        "    Give a binary score 'yes' or 'no'. 'Yes' means that the answer is grounded in / supported by the set of facts.\"\"\"\n",
        "hallucination_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"Set of facts: \\n\\n <facts>{documents}</facts> \\n\\n LLM generation: <generation>{generation}</generation>\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "hallucination_grader = hallucination_prompt | structured_llm_grader\n",
        "\n",
        "response = hallucination_grader.invoke({\"documents\": format_docs(docs_to_use), \"generation\": generation})\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aM49EWzNEUi"
      },
      "source": [
        "### Highlight used docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPL6fsg0NEUi"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "from langchain_core.output_parsers import PydanticOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "# Data model\n",
        "class HighlightDocuments(BaseModel):\n",
        "    \"\"\"Return the specific part of a document used for answering the question.\"\"\"\n",
        "\n",
        "    id: List[str] = Field(\n",
        "        ...,\n",
        "        description=\"List of id of docs used to answers the question\"\n",
        "    )\n",
        "\n",
        "    title: List[str] = Field(\n",
        "        ...,\n",
        "        description=\"List of titles used to answers the question\"\n",
        "    )\n",
        "\n",
        "    source: List[str] = Field(\n",
        "        ...,\n",
        "        description=\"List of sources used to answers the question\"\n",
        "    )\n",
        "\n",
        "    segment: List[str] = Field(\n",
        "        ...,\n",
        "        description=\"List of direct segements from used documents that answers the question\"\n",
        "    )\n",
        "\n",
        "# LLM\n",
        "llm = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0)\n",
        "\n",
        "# parser\n",
        "parser = PydanticOutputParser(pydantic_object=HighlightDocuments)\n",
        "\n",
        "# Prompt\n",
        "system = \"\"\"You are an advanced assistant for document search and retrieval. You are provided with the following:\n",
        "1. A question.\n",
        "2. A generated answer based on the question.\n",
        "3. A set of documents that were referenced in generating the answer.\n",
        "\n",
        "Your task is to identify and extract the exact inline segments from the provided documents that directly correspond to the content used to\n",
        "generate the given answer. The extracted segments must be verbatim snippets from the documents, ensuring a word-for-word match with the text\n",
        "in the provided documents.\n",
        "\n",
        "Ensure that:\n",
        "- (Important) Each segment is an exact match to a part of the document and is fully contained within the document text.\n",
        "- The relevance of each segment to the generated answer is clear and directly supports the answer provided.\n",
        "- (Important) If you didn't used the specific document don't mention it.\n",
        "\n",
        "Used documents: <docs>{documents}</docs> \\n\\n User question: <question>{question}</question> \\n\\n Generated answer: <answer>{generation}</answer>\n",
        "\n",
        "<format_instruction>\n",
        "{format_instructions}\n",
        "</format_instruction>\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template= system,\n",
        "    input_variables=[\"documents\", \"question\", \"generation\"],\n",
        "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
        ")\n",
        "\n",
        "# Chain\n",
        "doc_lookup = prompt | llm | parser\n",
        "\n",
        "# Run\n",
        "lookup_response = doc_lookup.invoke({\"documents\":format_docs(docs_to_use), \"question\": question, \"generation\": generation})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sn5pnxdkNEUi",
        "outputId": "cf450abe-781d-4630-9097-211d9d285a3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ID: doc3\n",
            "Title: Four AI Agent Strategies That Improve GPT-4 and GPT-3.5 Performance\n",
            "Source: https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/?ref=dl-staging-website.ghost.io\n",
            "Text Segment: Reflection: The LLM examines its own work to come up with ways to improve it.\\nTool Use: The LLM is given tools such as web search, code execution, or any other function to help it gather information, take action, or process data.\\nPlanning: The LLM comes up with, and executes, a multistep plan to achieve a goal (for example, writing an outline for an essay, then doing online research, then writing a draft, and so on).\\nMulti-agent collaboration: More than one AI agent work together, splitting up tasks and discussing and debating ideas, to come up with better solutions than a single agent would.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for id, title, source, segment in zip(lookup_response.id, lookup_response.title, lookup_response.source, lookup_response.segment):\n",
        "    print(f\"ID: {id}\\nTitle: {title}\\nSource: {source}\\nText Segment: {segment}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBi92dudNEUj"
      },
      "source": [
        "![](https://europe-west1-rag-techniques-views-tracker.cloudfunctions.net/rag-techniques-tracker?notebook=all-rag-techniques--reliable-rag)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
